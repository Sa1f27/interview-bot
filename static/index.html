<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interview</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            background: #1a1a2e;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            margin: 0;
            padding: 0;
            overflow: hidden;
        }

        .interview-container {
            display: flex;
            flex-direction: column;
            height: 100vh;
        }

        .video-section {
            flex: 1;
            position: relative;
            background: #0f0f1e;
            overflow: hidden;
        }

        #userVideo {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .ai-overlay {
            position: absolute;
            bottom: 100px;
            right: 30px;
            width: 200px;
            height: 200px;
            background: rgba(13, 110, 253, 0.9);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4);
            border: 4px solid white;
        }

        .ai-avatar {
            width: 150px;
            height: 150px;
            position: relative;
        }

        #statusIndicator {
            position: absolute;
            bottom: 5px;
            right: 5px;
            width: 35px;
            height: 35px;
            border-radius: 50%;
            background: #6c757d;
            border: 4px solid white;
            transition: all 0.3s;
        }

        #statusIndicator.listening {
            background: #dc3545;
            animation: pulse 1.5s infinite;
        }

        #statusIndicator.speaking {
            background: #28a745;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {

            0%,
            100% {
                box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.7);
            }

            50% {
                box-shadow: 0 0 0 20px rgba(220, 53, 69, 0);
            }
        }

        .subtitle-bar {
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            background: linear-gradient(to top, rgba(0, 0, 0, 0.9), transparent);
            padding: 40px 60px 30px;
            min-height: 120px;
            display: flex;
            flex-direction: column;
            justify-content: flex-end;
        }

        .subtitle-text {
            color: white;
            font-size: 1.5rem;
            text-align: center;
            text-shadow: 2px 2px 8px rgba(0, 0, 0, 0.8);
            line-height: 1.6;
            font-weight: 500;
            max-width: 90%;
            margin: 0 auto;
        }

        .subtitle-speaker {
            color: #ffd700;
            font-weight: 600;
            font-size: 1rem;
            text-align: center;
            margin-bottom: 8px;
            text-shadow: 1px 1px 4px rgba(0, 0, 0, 0.8);
        }

        .control-bar {
            background: rgba(26, 26, 46, 0.95);
            padding: 20px;
            text-align: center;
            border-top: 2px solid rgba(255, 255, 255, 0.1);
        }

        #startBtn,
        #endBtn {
            padding: 14px 40px;
            font-size: 1.1rem;
            border-radius: 25px;
            border: none;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 600;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
        }

        #startBtn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        #startBtn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
        }

        #endBtn {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
        }

        #endBtn:hover {
            transform: translateY(-2px);
        }

        .hidden {
            display: none !important;
        }

        .transcript-panel {
            position: absolute;
            top: 20px;
            right: 20px;
            width: 350px;
            max-height: 70vh;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 12px;
            padding: 20px;
            overflow-y: auto;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            backdrop-filter: blur(10px);
        }

        .transcript-panel h5 {
            margin: 0 0 15px 0;
            color: #1a1a2e;
            font-weight: 600;
        }

        .transcript-entry {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 8px;
            background: #f8f9fa;
            font-size: 0.9rem;
        }

        .transcript-entry.user {
            background: #e3f2fd;
        }

        .transcript-entry.ai {
            background: #f3e5f5;
        }

        .transcript-entry .role {
            font-weight: 600;
            margin-bottom: 4px;
            color: #495057;
            font-size: 0.85rem;
        }

        .transcript-entry .text {
            color: #212529;
            line-height: 1.4;
        }

        .camera-off-message {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            text-align: center;
            color: white;
            font-size: 1.5rem;
        }

        .camera-off-message svg {
            width: 100px;
            height: 100px;
            margin-bottom: 20px;
            opacity: 0.5;
        }

        ::-webkit-scrollbar {
            width: 8px;
        }

        ::-webkit-scrollbar-track {
            background: rgba(0, 0, 0, 0.1);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 4px;
        }
    </style>
</head>

<body>
    <div class="interview-container">
        <div class="video-section">
            <video id="userVideo" autoplay muted playsinline></video>
            <div class="camera-off-message" id="cameraOffMsg">
                <svg viewBox="0 0 24 24" fill="white">
                    <path
                        d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8zm-1-13h2v6h-2zm0 8h2v2h-2z" />
                </svg>
                <div>Camera will activate when interview starts</div>
            </div>

            <div class="ai-overlay">
                <div class="ai-avatar">
                    <svg viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                        <circle cx="50" cy="50" r="45" fill="white" />
                        <circle cx="35" cy="40" r="4" fill="#0d6efd" />
                        <circle cx="65" cy="40" r="4" fill="#0d6efd" />
                        <path id="mouth" d="M 32 62 Q 50 70 68 62" stroke="#0d6efd" stroke-width="3" fill="none"
                            stroke-linecap="round" />
                    </svg>
                    <div id="statusIndicator"></div>
                </div>
            </div>

            <div class="subtitle-bar" id="subtitleBar" style="opacity: 0;">
                <div class="subtitle-speaker" id="subtitleSpeaker"></div>
                <div class="subtitle-text" id="subtitleText"></div>
            </div>

            <div class="transcript-panel" id="transcriptPanel">
                <h5>üìù Transcript</h5>
            </div>
        </div>

        <div class="control-bar">
            <button id="startBtn">üé• Start Interview</button>
            <button id="endBtn" class="hidden">‚èπÔ∏è End Interview</button>
        </div>
    </div>

    <script>
        const startBtn = document.getElementById('startBtn');
        const endBtn = document.getElementById('endBtn');
        const transcriptPanel = document.getElementById('transcriptPanel');
        const statusIndicator = document.getElementById('statusIndicator');
        const mouth = document.getElementById('mouth');
        const userVideo = document.getElementById('userVideo');
        const cameraOffMsg = document.getElementById('cameraOffMsg');
        const subtitleBar = document.getElementById('subtitleBar');
        const subtitleText = document.getElementById('subtitleText');
        const subtitleSpeaker = document.getElementById('subtitleSpeaker');

        let testId = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let audioContext = null;
        let vadNode = null;
        let isRecording = false;
        let currentAudio = null;
        let videoStream = null;

        startBtn.addEventListener('click', startInterview);
        endBtn.addEventListener('click', endInterview);

        function showSubtitle(speaker, text) {
            subtitleSpeaker.textContent = speaker === 'AI' ? 'ü§ñ AI Interviewer' : 'üë§ You';
            subtitleText.textContent = text;
            subtitleBar.style.opacity = '1';

            setTimeout(() => {
                subtitleBar.style.opacity = '0';
            }, text.length * 50 + 2000);
        }

        function addTranscript(role, text) {
            const entry = document.createElement('div');
            entry.className = `transcript-entry ${role.toLowerCase()}`;
            entry.innerHTML = `
                <div class="role">${role === 'AI' ? 'ü§ñ AI' : role === 'You' ? 'üë§ You' : '‚öôÔ∏è System'}</div>
                <div class="text">${text}</div>
            `;
            transcriptPanel.appendChild(entry);
            transcriptPanel.scrollTop = transcriptPanel.scrollHeight;
        }

        async function startCamera() {
            try {
                videoStream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        facingMode: 'user'
                    }
                });
                userVideo.srcObject = videoStream;
                cameraOffMsg.style.display = 'none';
            } catch (error) {
                console.error('Camera error:', error);
                cameraOffMsg.innerHTML = '<svg viewBox="0 0 24 24" fill="white"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-2h2v2zm0-4h-2V7h2v6z"/></svg><div>Camera unavailable</div>';
            }
        }

        function stopCamera() {
            if (videoStream) {
                videoStream.getTracks().forEach(track => track.stop());
                videoStream = null;
                userVideo.srcObject = null;
                cameraOffMsg.style.display = 'block';
                cameraOffMsg.innerHTML = '<svg viewBox="0 0 24 24" fill="white"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8zm-1-13h2v6h-2zm0 8h2v2h-2z"/></svg><div>Camera off</div>';
            }
        }

        async function startInterview() {
            startBtn.classList.add('hidden');
            endBtn.classList.remove('hidden');

            await startCamera();

            statusIndicator.className = '';
            showSubtitle('System', 'Starting interview...');

            try {
                const response = await fetch('/start_test', { method: 'POST' });
                const data = await response.json();
                testId = data.test_id;

                addTranscript('AI', data.question);
                showSubtitle('AI', data.question);
                playAudio(data.audio_path, () => {
                    startRecording();
                });
            } catch (error) {
                console.error('Start error:', error);
                addTranscript('System', 'Error starting interview');
                showSubtitle('System', 'Error starting interview');
                resetUI();
            }
        }

        function endInterview() {
            stopRecording();
            stopCamera();
            showSubtitle('System', 'Interview ended. Thank you!');
            addTranscript('System', 'Interview ended');
            resetUI();
        }

        function resetUI() {
            startBtn.classList.remove('hidden');
            endBtn.classList.add('hidden');
            statusIndicator.className = '';
            testId = null;
            if (currentAudio) {
                currentAudio.pause();
                currentAudio = null;
            }
        }

        function playAudio(audioPath, callback) {
            if (!audioPath) {
                if (callback) callback();
                return;
            }

            statusIndicator.className = 'speaking';
            mouth.setAttribute('d', 'M 32 62 Q 50 75 68 62');

            currentAudio = new Audio(audioPath);
            currentAudio.onended = () => {
                mouth.setAttribute('d', 'M 32 62 Q 50 70 68 62');
                statusIndicator.className = '';
                currentAudio = null;
                if (callback) callback();
            };
            currentAudio.onerror = () => {
                console.error('Audio error');
                if (callback) callback();
            };
            currentAudio.play();
        }

        async function startRecording() {
            if (isRecording || !testId) return;
            isRecording = true;

            statusIndicator.className = 'listening';
            showSubtitle('System', 'Listening...');

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                audioContext = new AudioContext();
                await audioContext.audioWorklet.addModule('/static/vad-processor.js');

                const microphone = audioContext.createMediaStreamSource(stream);
                vadNode = new AudioWorkletNode(audioContext, 'vad-processor', {
                    processorOptions: {
                        voiceStopDelay: 2000,
                        speakingThreshold: 0.02,
                        minSpeakingDuration: 500
                    }
                });

                vadNode.port.onmessage = (event) => {
                    if (event.data.speaking === false) {
                        stopRecording();
                    }
                };

                microphone.connect(vadNode);

                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = () => {
                    stream.getTracks().forEach(track => track.stop());
                    sendAudioAndGetResponse();
                };

                mediaRecorder.start();
            } catch (error) {
                console.error('Recording error:', error);
                showSubtitle('System', 'Microphone error');
                isRecording = false;
            }
        }

        function stopRecording() {
            if (!isRecording) return;
            isRecording = false;

            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
            if (vadNode) {
                vadNode.disconnect();
                vadNode = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            statusIndicator.className = '';
            showSubtitle('System', 'Processing your response...');
        }

        async function sendAudioAndGetResponse() {
            if (audioChunks.length === 0) {
                startRecording();
                return;
            }

            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            audioChunks = [];

            try {
                const response = await fetch(`/interview/${testId}`, {
                    method: 'POST',
                    body: audioBlob
                });

                if (!response.ok) {
                    throw new Error(`Server error: ${response.status}`);
                }

                const data = await response.json();

                if (data.user_transcript) {
                    addTranscript('You', data.user_transcript);
                    showSubtitle('You', data.user_transcript);

                    setTimeout(() => {
                        addTranscript('AI', data.text);
                        showSubtitle('AI', data.text);
                    }, 1000);
                } else {
                    addTranscript('AI', data.text);
                    showSubtitle('AI', data.text);
                }

                if (data.ended) {
                    playAudio(data.audio_path, () => {
                        endInterview();
                    });
                } else {
                    playAudio(data.audio_path, () => {
                        startRecording();
                    });
                }
            } catch (error) {
                console.error('Interview error:', error);
                addTranscript('System', 'Error occurred');
                showSubtitle('System', 'Error. Retrying...');
                startRecording();
            }
        }
    </script>
</body>

</html>